\section{Combining interpolators and macros}
\subsection{Parameterized queries in PostgreSQL}
Before we can get to the part where our custom interpolator is a simple call to the macro, which does the validation, we have to talk about the implementation of placeholders in PostgreSQL. There is existing support for something called \textit{Prepared statements}. These allow for placeholders inside the query, in the form of \texttt{\$n} where \texttt{n} must be a positive integer.  

During compile time each variable in our interpolated string is known by name only. In macro, the first thing we have to do is build the string itself from the \texttt{StringContext} and the arguments. To keep the final query valid, each of the arguments has to be replaced with the placeholder \texttt{\$n}. 
Let's say we have the following example.
\begin{lstlisting}[language=scala, basicstyle=\ttfamily, showstringspaces=false, caption={Query with variable name.}]
query"SELECT $columnName FROM students"
\end{lstlisting}
If we tried to pass this string directly to the \textit{libpg\_query}, we would get an empty JSON result, because this is not a valid query. That means we have to transform it into this form.
\begin{lstlisting}[language=scala, basicstyle=\ttfamily, showstringspaces=false,
caption={Query with a placeholder.}]
query"SELECT $1 FROM students"
\end{lstlisting}
This returns the correct parse tree, where each of the placeholders contains a node of \texttt{ParamRef} type. 

\subsection{Validation of the query}
We are able to build the query string from the \texttt{StringContext} and passed arguments. To create a valid query, we have to enumerate the arguments. Each argument is replaced by placeholder starting from \texttt{\$1} up to \texttt{\$n}, where \texttt{n} is the total count of passed arguments. After we intersperse the placeholders into \texttt{List[String]} we can use the \texttt{parse} method from \texttt{PgQueryParser} for validation. If the query is valid, we get the parse tree representation in the form of a \texttt{Node}.

\subsection{Transforming syntax tree}
The parse tree now contains one \texttt{ParamRef} node for each argument. The next step is to replace these placeholder nodes with their corresponding arguments. Macros are required to return results in the form of \texttt{Tree}. The easiest solution is to \texttt{lift} the \texttt{Node} we got from \textit{libpg\_query} to AST representation and then replace the placeholders with the original arguments. 

For that purpose, we are going to use our custom class \texttt{ParamRefTransformer}. It extends the abstract class \texttt{Transformer}, which \textit{implements a default tree transformation strategy: breadth-first component-wise cloning}.\cite{Transformer} 

The \texttt{ParamRefTransformer} overrides the \texttt{transform} method, which takes one argument - the parse tree in form of a \texttt{Tree}. The method then iterates over each node of the \texttt{Tree} and matches the following pattern.
\begin{lstlisting}[language=scala, basicstyle=\ttfamily, showstringspaces=false, caption={Pattern of the AST of \texttt{ParamRef} node.}, xleftmargin=.05in]
q"ParamRef(${Literal(Constant(constant:Int))}, ${_})"
\end{lstlisting}
Whenever the pattern matches the current \texttt{Tree}, the whole \texttt{ParamRef} is replaced by the argument AST with same index as the \texttt{constant}. If the pattern doesn't match, the original method from the superclass is called. The original transform then applies the transform function again on each leaf of the current node.
This way, every node of the AST is traversed, and we replace each \texttt{ParamRef} node with the original argument.

\subsection{Type checking}
In the end, we have the finished SQL parse tree in the form of AST. 
The parsing in \texttt{PgQueryParser} ensures that the query is valid.
Within the tree, each placeholder is replaced with the original argument. The compiler then compares the type of the argument with the expected type in the context of the parse tree structure. If the type of the argument isn't correct, it throws the \textit{type mismatch} error.

\subsection{Implicit conversions}
Since we introduced the validation and type checking using the macro, we could only use interpolator, which uses the macro with arguments that are Node objects or a more specific type of \texttt{Node}, depending on where we try to insert it. That means if we wanted to define a function, which takes \texttt{String} as an argument, we couldn't use it in the interpolator. Instead, we had to parse it as an expression and only then pass it to the interpolator.

Fortunately, Scala provides \texttt{implicit} keyword that can be used to create the implicit conversion from one type to another. \textit{An implicit conversion from type S to type T is defined by an implicit value which has function type S $\rightarrow$ T, or by an implicit method convertible to a value of that type.}\cite{Implicit} Whenever the type of an expression does not conform to the expected type, compile attempts to find an implicit conversion function, which can be used to get the correct type. The order in which the compiler looks for the implicit conversion is as follows: \cite{Looking up Implicits}
\begin{enumerate}
  \item Implicits defined in the current scope
  \item Explicit imports (i.e. \texttt{import ImplicitConversions.int2string})
  \item Wildcard imports (i.e. \texttt{import ImplicitConversions.\_})
  \item Same scope in other files
\end{enumerate}

Currently the library supports implicit conversions from \texttt{String} and \texttt{Int} to \texttt{ResTarget} and \texttt{A\_Const} nodes. These nodes cover majority of possible expressions that can be used. The conversion from \texttt{String} to \texttt{ResTarget} uses another macro, which validates the expression. The rest creates the desired objects directly.


